{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Анализ тональности с BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание исследования\n",
    "\n",
    "Интернет-магазин «Викишоп» запускает новый сервис. Пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. Клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Цель исследования\n",
    "\n",
    "- Обучить модель классифицировать комментарии как позитивные или негативные. Построить модель со значением метрики качества F1 не меньше 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ход исследования\n",
    "\n",
    "1. Загрузка и подготовка данных\n",
    "2. Обучение моделей\n",
    "2. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание данных\n",
    "\n",
    "- 'text' - текст комментарий\n",
    "- 'toxic' - целевой признак, является ли комментарий токсичным"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_id'></a>\n",
    "## Содержание \n",
    "\n",
    "[Шаг 1. Загрузка данных](#section_id1)\n",
    "\n",
    "[Шаг 2. Предобработка и исследовательский анализ](#section_id2)\n",
    "\n",
    "[Шаг 3. Подготовка данных](#section_id3)\n",
    "\n",
    "[Шаг 4. Обучение моделей](#section_id4)\n",
    "\n",
    "[Шаг 5. Проверка на тестовой выборке](#section_id5)\n",
    "\n",
    "[Шаг 6. Вывод](#section_id6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт библиотек\n",
    "\n",
    "# работа с данными\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# подготовка данных\n",
    "from sklearn.model_selection import train_test_split\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "# модели машинного обучения\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# пайплайны\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# инструменты поиска\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# инструменты управления ресурсами\n",
    "import joblib\n",
    "import warnings\n",
    "from tqdm import notebook\n",
    "\n",
    "# метрика для оценки прогноза\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# константы\n",
    "TEST_SIZE = 0.25 \n",
    "RANDOM_STATE = 42\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "# настройки\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_id1'></a>\n",
    "## Шаг 1. Загрузка данных\n",
    "[к содержанию](#section_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загрузка данных\n",
    "df = pd.read_csv('..\\\\data\\\\toxic_comments.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_id2'></a>\n",
    "## Шаг 2. Предобработка и исследовательский анализ\n",
    "[к содержанию](#section_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаление столбца без названия и сокращение датасета\n",
    "df = df[['text', 'toxic']].sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для обзора данных\n",
    "def preview(dataset):\n",
    "    '''Функция принимает на вход набор данных и выводит основную информацию о нем.'''\n",
    "    display(dataset.head())\n",
    "    dataset.info()\n",
    "    display(dataset.describe(include='all').T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69682</th>\n",
       "      <td>\"\\n Okay, it's clear English is your second la...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120861</th>\n",
       "      <td>do you mean by seems to? More like does, dumba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149311</th>\n",
       "      <td>What did I say that was incorrect about the Sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138485</th>\n",
       "      <td>Just an idea now, it will come soon.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142501</th>\n",
       "      <td>, 12 Apr 2005 (UTC)\\n\\nIf the claim is that th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "69682   \"\\n Okay, it's clear English is your second la...      0\n",
       "120861  do you mean by seems to? More like does, dumba...      1\n",
       "149311  What did I say that was incorrect about the Sa...      0\n",
       "138485               Just an idea now, it will come soon.      0\n",
       "142501  , 12 Apr 2005 (UTC)\\n\\nIf the claim is that th...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1000 entries, 69682 to 138304\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    1000 non-null   object\n",
      " 1   toxic   1000 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 23.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>I am working from sources. I'm not sure about ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.32745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count unique                                                top freq  \\\n",
       "text     1000   1000  I am working from sources. I'm not sure about ...    1   \n",
       "toxic  1000.0    NaN                                                NaN  NaN   \n",
       "\n",
       "        mean      std  min  25%  50%  75%  max  \n",
       "text     NaN      NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "toxic  0.122  0.32745  0.0  0.0  0.0  0.0  1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# обзор данных\n",
    "preview(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic\n",
       "0    878\n",
       "1    122\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# определение баланса классов\n",
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы о данных:\n",
    "- пропусков нет\n",
    "- повторяющихся комментариев нет\n",
    "- типы данных приведены верно\n",
    "- баланс классов смещен в сторону нетоксичных комментариев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_id3'></a>\n",
    "## Шаг 3. Подготовка данных\n",
    "[к содержанию](#section_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализация токенизатора\n",
    "tokenizer = transformers.BertTokenizer(\n",
    "    vocab_file='..\\\\data\\\\bert\\\\vocab.txt')\n",
    "\n",
    "# запуск токенизации\n",
    "tokenized = df['text'].apply(\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
    "\n",
    "# определение максимальной длины вектора\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "# дополнение векторов меньшей длины нулями\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "# срез по размерности токенов\n",
    "padded = padded[:, :512]\n",
    "\n",
    "# создание маски внимания\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 512)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализация конфигурации\n",
    "config = transformers.BertConfig.from_json_file(\n",
    "    '..\\\\data\\\\bert\\\\config.json')\n",
    "\n",
    "# инициализация модели\n",
    "model = transformers.BertModel.from_pretrained(\n",
    "    '..\\\\data\\\\bert\\\\pytorch_model.bin', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c9ef919b522426b95bb3ac4fae34970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# создание эмбедингов\n",
    "embeddings = []\n",
    "\n",
    "with joblib.parallel_backend(\"threading\"):\n",
    "    for i in notebook.tqdm(range(padded.shape[0] // BATCH_SIZE)):\n",
    "            batch = torch.LongTensor(padded[BATCH_SIZE*i:BATCH_SIZE*(i+1)]) \n",
    "            attention_mask_batch = torch.LongTensor(attention_mask[BATCH_SIZE*i:BATCH_SIZE*(i+1)])\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "            \n",
    "            embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сборка признаков\n",
    "features = np.concatenate(embeddings)\n",
    "\n",
    "# разбиение на тренировочную и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features,\n",
    "    df['toxic'],\n",
    "    test_size = TEST_SIZE,\n",
    "    stratify=df['toxic'],\n",
    "    random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_id4'></a>\n",
    "## Шаг 4. Обучение моделей\n",
    "[к содержанию](#section_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пайплайн обучения\n",
    "pipe_final = Pipeline([\n",
    "    ('models', LogisticRegression(random_state=RANDOM_STATE))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# задание параметров для пайплайна\n",
    "param_grid = [\n",
    "    # словарь для модели LogisticRegression()\n",
    "    {\n",
    "        'models': [LogisticRegression(\n",
    "            random_state=RANDOM_STATE,\n",
    "            solver='liblinear',\n",
    "            penalty='l2'\n",
    "        )],\n",
    "        'models__C': [5, 10, 15],\n",
    "    },\n",
    "    \n",
    "    # словарь для модели DecisionTreeClassifier()\n",
    "    {\n",
    "        'models': [DecisionTreeClassifier(random_state=RANDOM_STATE)],\n",
    "        'models__max_features': range(6, 8),\n",
    "        'models__max_depth': range(8, 10)\n",
    "    },\n",
    "    \n",
    "    # словарь для модели KNeighborsClassifier() \n",
    "    {\n",
    "        'models': [KNeighborsClassifier()],\n",
    "        'models__n_neighbors': [5, 25]   \n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализация подбора параметров\n",
    "grid_search = GridSearchCV(\n",
    "    pipe_final, \n",
    "    param_grid, \n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Лучшая модель и её параметры:\n",
      "\n",
      " Pipeline(steps=[('models',\n",
      "                 LogisticRegression(C=5, random_state=42, solver='liblinear'))])\n",
      "Метрика лучшей модели на тренировочной выборке: 0.5463741177867985\n",
      "CPU times: total: 14.5 s\n",
      "Wall time: 3.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# запуск подбора параметров\n",
    "with joblib.parallel_backend(\"threading\"):\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Лучшая модель и её параметры:\\n\\n', grid_search.best_estimator_)\n",
    "print ('Метрика лучшей модели на тренировочной выборке:', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_models</th>\n",
       "      <th>param_models__C</th>\n",
       "      <th>param_models__max_depth</th>\n",
       "      <th>param_models__max_features</th>\n",
       "      <th>param_models__n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.840721</td>\n",
       "      <td>0.117201</td>\n",
       "      <td>0.014634</td>\n",
       "      <td>0.007756</td>\n",
       "      <td>LogisticRegression(random_state=42, solver='li...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'models': LogisticRegression(random_state=42,...</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.546374</td>\n",
       "      <td>0.113126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.799845</td>\n",
       "      <td>0.053563</td>\n",
       "      <td>0.008203</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>LogisticRegression(random_state=42, solver='li...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'models': LogisticRegression(random_state=42,...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.528430</td>\n",
       "      <td>0.122033</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.725678</td>\n",
       "      <td>0.036819</td>\n",
       "      <td>0.008806</td>\n",
       "      <td>0.004705</td>\n",
       "      <td>LogisticRegression(random_state=42, solver='li...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'models': LogisticRegression(random_state=42,...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.520309</td>\n",
       "      <td>0.121916</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.020434</td>\n",
       "      <td>0.010835</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>DecisionTreeClassifier(random_state=42)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'models': DecisionTreeClassifier(random_state...</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.259676</td>\n",
       "      <td>0.056714</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.012887</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.004839</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>DecisionTreeClassifier(random_state=42)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'models': DecisionTreeClassifier(random_state...</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.256119</td>\n",
       "      <td>0.037314</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.011990</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>0.004806</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>DecisionTreeClassifier(random_state=42)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'models': DecisionTreeClassifier(random_state...</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.243077</td>\n",
       "      <td>0.054483</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012439</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>0.005833</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>DecisionTreeClassifier(random_state=42)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'models': DecisionTreeClassifier(random_state...</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.208406</td>\n",
       "      <td>0.103215</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.010210</td>\n",
       "      <td>0.003553</td>\n",
       "      <td>1.085882</td>\n",
       "      <td>0.056478</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'models': KNeighborsClassifier(), 'models__n_...</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.181133</td>\n",
       "      <td>0.107313</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.009018</td>\n",
       "      <td>0.003193</td>\n",
       "      <td>0.611344</td>\n",
       "      <td>0.465054</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>{'models': KNeighborsClassifier(), 'models__n_...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.840721      0.117201         0.014634        0.007756   \n",
       "1       0.799845      0.053563         0.008203        0.003475   \n",
       "2       0.725678      0.036819         0.008806        0.004705   \n",
       "3       0.020434      0.010835         0.004444        0.000552   \n",
       "6       0.012887      0.001389         0.004839        0.000709   \n",
       "5       0.011990      0.001650         0.004806        0.000659   \n",
       "4       0.012439      0.001544         0.005833        0.001963   \n",
       "7       0.010210      0.003553         1.085882        0.056478   \n",
       "8       0.009018      0.003193         0.611344        0.465054   \n",
       "\n",
       "                                        param_models  param_models__C  \\\n",
       "0  LogisticRegression(random_state=42, solver='li...              5.0   \n",
       "1  LogisticRegression(random_state=42, solver='li...             10.0   \n",
       "2  LogisticRegression(random_state=42, solver='li...             15.0   \n",
       "3            DecisionTreeClassifier(random_state=42)              NaN   \n",
       "6            DecisionTreeClassifier(random_state=42)              NaN   \n",
       "5            DecisionTreeClassifier(random_state=42)              NaN   \n",
       "4            DecisionTreeClassifier(random_state=42)              NaN   \n",
       "7                             KNeighborsClassifier()              NaN   \n",
       "8                             KNeighborsClassifier()              NaN   \n",
       "\n",
       "   param_models__max_depth  param_models__max_features  \\\n",
       "0                      NaN                         NaN   \n",
       "1                      NaN                         NaN   \n",
       "2                      NaN                         NaN   \n",
       "3                      8.0                         6.0   \n",
       "6                      9.0                         7.0   \n",
       "5                      9.0                         6.0   \n",
       "4                      8.0                         7.0   \n",
       "7                      NaN                         NaN   \n",
       "8                      NaN                         NaN   \n",
       "\n",
       "   param_models__n_neighbors  \\\n",
       "0                        NaN   \n",
       "1                        NaN   \n",
       "2                        NaN   \n",
       "3                        NaN   \n",
       "6                        NaN   \n",
       "5                        NaN   \n",
       "4                        NaN   \n",
       "7                        5.0   \n",
       "8                       25.0   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'models': LogisticRegression(random_state=42,...           0.620690   \n",
       "1  {'models': LogisticRegression(random_state=42,...           0.600000   \n",
       "2  {'models': LogisticRegression(random_state=42,...           0.600000   \n",
       "3  {'models': DecisionTreeClassifier(random_state...           0.285714   \n",
       "6  {'models': DecisionTreeClassifier(random_state...           0.227273   \n",
       "5  {'models': DecisionTreeClassifier(random_state...           0.242424   \n",
       "4  {'models': DecisionTreeClassifier(random_state...           0.187500   \n",
       "7  {'models': KNeighborsClassifier(), 'models__n_...           0.181818   \n",
       "8  {'models': KNeighborsClassifier(), 'models__n_...           0.000000   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.611111           0.322581           0.571429           0.606061   \n",
       "1           0.578947           0.285714           0.571429           0.606061   \n",
       "2           0.564103           0.277778           0.571429           0.588235   \n",
       "3           0.222222           0.352941           0.250000           0.187500   \n",
       "6           0.235294           0.216216           0.307692           0.294118   \n",
       "5           0.333333           0.263158           0.200000           0.176471   \n",
       "4           0.279070           0.068966           0.363636           0.142857   \n",
       "7           0.320000           0.153846           0.000000           0.250000   \n",
       "8           0.000000           0.000000           0.000000           0.000000   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.546374        0.113126                1  \n",
       "1         0.528430        0.122033                2  \n",
       "2         0.520309        0.121916                3  \n",
       "3         0.259676        0.056714                4  \n",
       "6         0.256119        0.037314                5  \n",
       "5         0.243077        0.054483                6  \n",
       "4         0.208406        0.103215                7  \n",
       "7         0.181133        0.107313                8  \n",
       "8         0.000000        0.000000                9  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получение результатов лучших моделей\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "results.sort_values(by='rank_test_score', inplace=True)\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_id5'></a>\n",
    "## Шаг 5. Проверка на тестовой выборке\n",
    "[к содержанию](#section_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 тестовой выборки: 0.5\n"
     ]
    }
   ],
   "source": [
    "# проверка лучшей модели на тестовой выборке\n",
    "pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "print(\"f1 тестовой выборки:\", f1_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_id6'></a>\n",
    "## Шаг 6. Вывод\n",
    "[к содержанию](#section_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решена задача по классификации токсичных комментариев. При создании тренировочной и тестовой выборки выявлено, что токсичных коментариев значительно меньше, поэтому применена стратификация, чтобы равномерно распределить комментарии каждого класса по выборкам. Лемматизация произведена с помощью pymystem3 внутри функции, фильтровались специальные символы и стоп-слова. Для получения наборов признаков для обучения моделей использовался CountVectorizer, так как он показал лучшие результаты в сравнении с TfIdfVectorizer. Обучение производилось в пайплайне: исследовались модели LogisticRegression, DecisionTreeClassifier, KNeighborsClassifier. Лучшей моделью стала LogisticRegression с параметром регуляризации C=15. Неплохие результаты показала модель KNeighborsClassifier с параметрами n_neighbors=5. На тестовой выборке лучшая модель показала значение метрики f1_score равным 0.78"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
